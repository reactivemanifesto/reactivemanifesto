# 反应式宣言 词汇表

* [异步的](#异步的)
* [回压](#背压)
* [批量处理](#批量处理)
* [组件](#组件)
* [委派](#委派)
* [适应性（与“可伸缩性”对照）](#适应性)
* [失败（与“错误”对照）](#失败)
* [隔离（以及“遏制”）](#隔离)
* [位置透明性](#位置透明性)
* [消息驱动（与“事件驱动”对照）](#消息驱动)
* [非阻塞的](#非阻塞的)
* [协议](#协议)
* [复制](#复制)
* [资源](#资源)
* [可伸缩性](#可伸缩性)
* [系统](#系统)
* [用户](#用户)

## <a name="异步的"></a>异步的
牛津词典把“asynchronous（异步的）”定义为“**不同时存在或发生的**”。
在这个宣言的上下文中，我们的意思是：在来自客户端的请求被发送到了服务器之后，对于该请求的处理可以发生这之后的任意时间点。
对于发生在服务内部的执行过程，客户端无法直接地观察到，或者与之进行同步。
这是同步处理（synchronous processing）的反义词，
同步处理意味着客户端只能在服务已经处理完成该请求之后，才能继续恢复他自己的执行。

## <a name="回压"></a>回压
当某个[组件](#组件)正竭力地（struggling）跟上（负载或者接受请求的速率）时，
整个[系统](#系统)就需要以合理地方式做出反应。
对于该正在承受压力的组件来说，进行灾难性地失败，或者不受控地丢弃消息，都是不能接受的。
因为他既不能成功地应对，又不能（直接地）失败，
所以他需要向其上游组件传达其正在遭受压力的事实，并让他们降低负载。
这种回压（back-pressure）是一种重要的反馈机制，
其使得系统得以优雅地响应负载，而不是在负载下崩溃。
回压可以一路级联到（发起请求的）用户，
在这时，响应性可能会被降级，但是这种机制将确保系统在负载之下的弹性，
并将提供可能允许系统本身通过利用其他资源来帮助分担负载的信息，参见[适应性](#适应性)。

## <a name="批量处理"></a>批量处理
当前的电脑为反复执行同一项任务而进行了优化：
在（CPU）时钟频率保持不变的情况下，指令缓存和分支预测增加了每秒钟内可以被处理的指令数。
这就意味着将不同的任务快速连续地递交给相同的CPU核心将不能从本来可以实现的完全（最高利用率的）性能中获益：
如果可能，我们应该构造这样的应用程序，他的执行逻辑在不同的任务之间交替的频率更低。
这就意味着可以成批地处理一组数据元素，
这也就意味可以在专门的硬件线程（执CPU的逻辑核心）上执行不同处理步骤。

同样的推理也适用于需要同步和协调的外部[资源](#资源)的使用。
当从一个单一的线程（也就是CPU核心）发送指令，而不是从所有的CPU核心争夺带宽时，
由持久化存储设备所提供的I/O带宽将可以显著地提高。
使用一个单一的入口的附加优势是，
操作可以被重新排序，
以更好地适应设备的最佳访问模式（当前的存储设备的线性存取性能优于随机存取）。

此外，
批量处理提供了分摊昂贵的操作（如I/O）或者计算的成本的机会。
例如，
将多个数据项打包到同一个网络数据包或者磁盘存储块中，
以显著地提高效率并降低使用率。

## <a name="组件"></a>组件
我们所描述的是一个模块化的软件体系架构，其是一个非常古老的想法，
参见如[Parnas(1972)](https://www.cs.umd.edu/class/spring2003/cmsc838p/Design/criteria.pdf)。
我们正使用"组件"这个术语，
因为它和"隔离"的紧密相连，
"隔离"代表着每个组件都是自包含的、封装好的并和其他的组件相互[隔离](#隔离)。
虽然这个概念首先适用于系统的运行时特征，
但是它也通常会反映在源代码的模块化结构中。
虽然不同的组件可能会使用相同的软件模块来执行常见的任务，
但是定义了每个组件的顶层行为的程序代码则它自己也是一个模块。
组件边界通常与问题域中的[Bounded Context](http://martinfowler.com/bliki/BoundedContext.html)密切相关。
这意味着系统设计倾向于反应问题域，
并因此在保持隔离的同时更容易演化。
消息[协议](#协议)为多个[Bounded Context](http://martinfowler.com/bliki/BoundedContext.html)(组件)之间提供了自然的映射和通讯层。

## <a name="委派"></a>委派
将任务[异步地](#异步的)委派给另一个[组件](#组件)意味着该任务的执行将会发生在另一个组件中，
举几个可能的例子：
该被委派的上下文，
可能需要在一个不同的错误处理上下文中、在一个不同的线程上、在一个不同的进程中或者在一个不同的网络节点上运行。
委派的目的是将处理某个任务的责任移交给另一个组件，
以便发起委派的组件可以执行其他的处理、
或者有选择性地观察被委派的任务的进度，
以防需要执行额外的操作（如处理失败或者报告进度）。

## <a name="适应性"></a>适应性（与"可伸缩性"对照）
适应性意味着根据需求当资源按按比例的增加或者减少时，
系统的吞吐量将自动地向上或者向下缩放，
以满足不同的需求。
系统需要具有可伸缩性（参见[可伸缩性](#可伸缩性)），
以允许其从动态地添加或者删除资源中获益。
因此，适应性是建立在可伸缩性的基础之上的，
并通过添加自动地资源管理概念对其进行了扩充。

## <a name="失败"></a>失败（与“错误”对照）
失败是服务中的意外事件，其阻止了服务继续正常运行。
失败通常会阻止对于当前的、并可能所有接下来的客户端请求的响应。
和错误相对照，错误是意料之中的，并可以针对性编码的情况——例如，
在输入验证的过程中所发现的错误，
将作为消息的正常处理过程的一部分返回给客户端。
失败时意料之外的，
并且在系统能够恢复至（与之前）服务水平之前，需要进行干预。
这并不意味着失败总是致命的（fatal），
虽然在失败发生之后，
系统的一些能力可能会被降级。
错误是正常操作流程的预期部分，
在错误发生之后，
系统将会立即对其进行处理，
并将继续以相同的能力继续运行。

失败的例子有：硬件故障、由于资源耗尽而引起的进程的意外终止，以及导致内部状态损坏的程序缺陷。

## <a name="隔离"></a>隔离（以及"遏制"）
隔离可以定义为在时间和空间上的解耦。
在时间上的解耦意味着发送者和接收者可以拥有独立的生命周期——
他们不需要在同时存在以使相互通信成为可能。
通过在组件之间添加异步边界，
并通过消息传递实现了这一点。
空间上的解耦（定义为位置透明）意味着发送者和接收者不必运行在同一个进程中。
不管运维部门或者运行时本身决策的部署结构是多么的高效——
在应用程序的生命周期之类，这一切都可能会改变。

真正的隔离超出了大多数面向对象的语言中的常见的封装概念，
使得我们可以分隔和遏制：

- 状态和行为：它实现了无共享的设计，并最大限度地减少竞争和一致性成本（[如普遍性的伸缩性原则](http://www.perfdynamics.com/Manifesto/USLscalability.html)(Universal Scalability Law)中所定义的）。
- 失败：它允许在细粒度上捕获、发出信号和管理失败，而而不用将其扩散到其他组件。

组件之间的强隔离是建立在良好定义的协议之上的，
并实现了解耦，
从而使得系统更加容易被理解、扩展、测试和演化。

## <a name="位置透明性"></a>位置透明性
适应性系统需要自适应，
并不间断地对需求的变化做出反应。
他们需要优雅而高效地增加或者缩减（部署）规模。
极大地简化这个问题的一个关键洞察是认识到我们一直都在处理分布式计算。
无论我们是在在一台单独的（具有多个独立的通过快速通道互联（QPI）进行通信的CPU的）节点之上，
还是在一个（具有多台通过网络进行通信的独立节点的）机器集群之上运行我们的系统，
都是如此。
拥抱这一事实意味着，
在多核心之上进行垂直伸缩和在集群之上进行水平伸缩并没有什么概念是的差异。

如果我们所有的组件都支持移动性，
那么本地通信将只是一项优化而已。
因此，我们不需要预先定义一个静态的系统拓扑和部署结构。
可以将这个决策留给运维人员或者运行时，
他们可以根据系统的使用情况来对其进行调整和优化。

这种通过异步的消息传递实现的空间上的（请参阅隔离的定义），
以及运行时实例和他们的引用的解耦就是我们所谓的位置透明性。
位置透明性通常被误认为是“透明地分布式计算”，
然而实际上恰恰相反：
我们拥抱网络，以及它所有的约束——如部分失败、网络分裂、消息丢失，
以及它的异步性和与生俱来的基于消息的性质——
通过将他们作为编程模型中的一等公民，
而不是尝试在网络上模拟进程内的方法调用（如RPC、XA等）。
我们对于位置透明性的观点与Waldo等人的[A Note On Distributed Computing](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.7628)完全一致。


## <a name="消息驱动"></a>消息驱动（与事件驱动相对照）
消息是发送到特定目的地的数据项，
事件是组件在达到某个给定状态时所发出的型号。
在消息驱动的系统中，
可寻址的接收者等待消息的到来，
并对他们做出反应，
否则只是休眠（即异步非阻塞地等待消息的到来）。
在事件驱动的系统中，
通知监听器被附加到了事件源，
以便在事件被发出时调用他们。
这也就意味着，
事件驱动的系统关注于可寻址的事件源，
而消息驱动的系统则重点于可寻址的接收者。
消息可以将事件编码为它的有效载荷。


在事件驱动的系统中，
由于事件消耗链的短暂性，
很难实现弹性。
——当处理过程已经开始，
而且监听器已经设置好，以便对响应结果并对结果进行变换时，
这些监听器通常都直接地处理成功或者失败，
并向原始的客户端报告执行结果。
响应组件的失败，
以便于恢复失败组件的正常功能，，
在另外一方面，
需要处理的是
那些并没有与短暂的客户端请求捆绑在一起的，
而是影响了整个组件的健康状况的失败。

## <a name="非阻塞的"></a>非阻塞的
在并发编程中，
如果争夺资源的线程并没有被保护该资源的互斥所无限期地推迟执行，
那么该算法则被认为是非阻塞的。
在实践中，
这通常说缩影为一个 API，
当资源可用时，
其允许访问该资源，
否则，它将会立即地返回，
并通知调用者该资源当前不可用，
或者，该操作已经启动了但是还没有完成。
对于资源的非阻塞 API 使得调用者可以进行其他的操作，
而不是被阻塞以等待该资源便得可用。
这可以通过允许资源客户端注册，
以便在该资源可用的或者该操作已经完成时获得通知。

## <a name="协议"></a>协议

协议定义了在[组件](#组件)之间交换或者传输消息的方法与规范。
协议由会话参与者之间的关系、
协议的累计状态
以及可以发送的消息所组成。
这意味着协议描述了会话参与者在何时可以发送什么样的消息给另外一个会话参与者。
协议可以按照消息交换的形式进行分类，
一些常见的类型是请求——响应模式、
重复的请求——响应模式（如 HTTP 中）、
发布——订阅模式、
以及（反应式）流模式（包含（动态地）推送和拉取）。

和本地编程接口相比，
协议更加通用，
因为它可以包含两个以上的参与者，
并且可以预见到消息交换的进展，
而接口只指定调用者和接收者之间每次一次的交互。

需要注意的是，
这里所定义的协议指示制定了什么样的消息可能会被发送，
而不是他们应该如何被编码、解码（即编解码器），
而传输机制对于使用该协议的组件来说是透明的。

## <a name="复制"></a>复制

在不同的地方同时地执行一个组件被称为复制。
这可能意味着在不同的线程或者线程池、进程、网络节点或者计算中心中执行。
复制提供了可伸缩性，
其中传入的工作负载将跨组件的多个实例分布，
以及弹性，
其中传入的工作负载将被复制到多个并行地处理相同请求的多个实例。
这些方式可以结合使用，
例如，
确保该组件的某个确定用户的所有相关事务应该由两个实例执行，
与此同时，实例的总数则又根据传入的负载而变化（参见适应性）。

## <a name="资源"></a>资源

组件执行其功能说依赖的一切都可以都是资源，
资源必须要根据组件的需要而进行调配。
这包括 CPU 的分配、内存以及持久化存储以及网络带宽、
内存带宽、CPU 缓存、内部插座的 CPU 链接、可靠的计时器以及任务调度服务、
其他的输入和输出设备、外部服务（如数据库或者网络文件系统等）。
所有的这些资源都必须要考虑到适应性和弹性，
因为缺少必要的资源将会妨碍组件在被需要的时候发挥正常作用。


## <a name="可伸缩性"></a>可伸缩性

一个系统通过利用更多的计算资源来提升它的性能的能力，
是系统吞吐量的提升对上通资源的增加的比值来衡量的。
一个完美的可伸缩性系统中，
这两个数字是成正比的。
所分配的资源加倍，
也将使得吞吐量翻倍。
可伸缩性通常受限于系统中所引入的瓶颈或者同步点，
常见 Amdahl 定律以及 Gunther的通用可伸缩模型。


## <a name="系统"></a>系统

系统为它的用户或者客户端提供服务。
系统可大可小，
他们可以包含许多组件或者只是少数几个组件。
系统中的所有组件相互协作以提供这些服务。
在很多情况下，
相同系统中的组件都拥有某种客户端——服务器关系（例如考虑一下，前端组件依赖于后端组件）。

系统将共享了一个通用的弹性模型，
我们的意思是、
某个组件的失败将会在该系统的内部得到处理，
并从一个组件委派给另外一个组件。
如果系统中的一组组件的功能、资源或者失败模型都和系统中的其余部分相互隔离，
那么将这组组件看作是系统的子系统将有所脾益。


## <a name="用户"></a>用户
我们使用这个术语非正式地指代服务的任何消费者，可以是人或者其他服务。


















