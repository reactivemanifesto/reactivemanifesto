# 反应式宣言 词汇表

* [异步的](#异步的)
* [回压](#背压)
* [批量处理](#批量处理)
* [组件](#组件)
* [委派](#委派)
* [适应性（与“可伸缩性”对照）](#适应性)
* [失败（与“错误”对照）](#失败)
* [隔离（以及“遏制”）](#隔离)
* [位置透明性](#位置透明性)
* [消息驱动（与“事件驱动”对照）](#消息驱动)
* [非阻塞的](#非阻塞的)
* [协议](#协议)
* [复制](#复制)
* [资源](#资源)
* [可伸缩性](#可伸缩性)
* [系统](#系统)
* [用户](#用户)

## <a name="异步的"></a>异步的
牛津词典把“asynchronous（异步的）”定义为“**不同时存在或发生的**”。
在这个宣言的上下文中，我们的意思是：在来自客户端的请求被发送到了服务器之后，对于该请求的处理可以发生这之后的任意时间点。
对于发生在服务内部的执行过程，客户端无法直接地观察到，或者与之进行同步。
这是同步处理（synchronous processing）的反义词，
同步处理意味着客户端只能在服务已经处理完成该请求之后，才能继续恢复他自己的执行。

## <a name="回压"></a>回压
当某个[组件](#组件)正竭力地（struggling）跟上（负载或者接受请求的速率）时，
整个[系统](#系统)就需要以合理地方式做出反应。
对于该正在承受压力的组件来说，进行灾难性地失败，或者不受控地丢弃消息，都是不能接受的。
因为他既不能成功地应对，又不能（直接地）失败，
所以他需要向其上游组件传达其正在遭受压力的事实，并让他们降低负载。
这种回压（back-pressure）是一种重要的反馈机制，
其使得系统得以优雅地响应负载，而不是在负载下崩溃。
回压可以一路级联到（发起请求的）用户，
在这时，响应性可能会被降级，但是这种机制将确保系统在负载之下的弹性，
并将提供可能允许系统本身通过利用其他资源来帮助分担负载的信息，参见[适应性](#适应性)。

## <a name="批量处理"></a>批量处理
当前的电脑为反复执行同一项任务而进行了优化：
在（CPU）时钟频率保持不变的情况下，指令缓存和分支预测增加了每秒钟内可以被处理的指令数。
这就意味着将不同的任务快速连续地递交给相同的CPU核心将不能从本来可以实现的完全（最高利用率的）性能中获益：
如果可能，我们应该构造这样的应用程序，他的执行逻辑在不同的任务之间交替的频率更低。
这就意味着可以成批地处理一组数据元素，
这也就意味可以在专门的硬件线程（执CPU的逻辑核心）上执行不同处理步骤。

同样的推理也适用于需要同步和协调的外部[资源](#资源)的使用。
当从一个单一的线程（也就是CPU核心）发送指令，而不是从所有的CPU核心争夺带宽时，
由持久化存储设备所提供的I/O带宽将可以显著地提高。
使用一个单一的入口的附加优势是，
操作可以被重新排序，
以更好地适应设备的最佳访问模式（当前的存储设备的线性存取性能优于随机存取）。

此外，
批量处理提供了分摊昂贵的操作（如I/O）或者计算的成本的机会。
例如，
将多个数据项打包到同一个网络数据包或者磁盘存储块中，
以显著地提高效率并降低使用率。

## <a name="组件"></a>组件
我们所描述的是一个模块化的软件体系架构，其是一个非常古老的想法，
参见如[Parnas(1972)](https://www.cs.umd.edu/class/spring2003/cmsc838p/Design/criteria.pdf)。
我们正使用"组件"这个术语，
因为它和"隔离"的紧密相连，
"隔离"代表着每个组件都是自包含的、封装好的并和其他的组件相互[隔离](#隔离)。
虽然这个概念首先适用于系统的运行时特征，
但是它也通常会反映在源代码的模块化结构中。
虽然不同的组件可能会使用相同的软件模块来执行常见的任务，
但是定义了每个组件的顶层行为的程序代码则它自己也是一个模块。
组件边界通常与问题域中的[Bounded Context](http://martinfowler.com/bliki/BoundedContext.html)密切相关。
这意味着系统设计倾向于反应问题域，
并因此在保持隔离的同时更容易演化。
消息[协议](#协议)为多个[Bounded Context](http://martinfowler.com/bliki/BoundedContext.html)(组件)之间提供了自然的映射和通讯层。

## <a name="委派"></a>委派
将任务[异步地](#异步的)委派给另一个[组件](#组件)意味着该任务的执行将会发生在另一个组件中，
举几个可能的例子：
该被委派的上下文，
可能需要在一个不同的错误处理上下文中、在一个不同的线程上、在一个不同的进程中或者在一个不同的网络节点上运行。
委派的目的是将处理某个任务的责任移交给另一个组件，
以便发起委派的组件可以执行其他的处理、
或者有选择性地观察被委派的任务的进度，
以防需要执行额外的操作（如处理失败或者报告进度）。

## <a name="适应性"></a>适应性（与"可伸缩性"对照）
适应性意味着根据需求当资源按按比例的增加或者减少时，
系统的吞吐量将自动地向上或者向下缩放，
以满足不同的需求。
系统需要具有可伸缩性（参见[可伸缩性](#可伸缩性)），
以允许其从动态地添加或者删除资源中获益。
因此，适应性是建立在可伸缩性的基础之上的，
并通过添加自动地资源管理概念对其进行了扩充。

## <a name="失败"></a>失败（与“错误”对照）
失败是服务中的意外事件，其阻止了服务继续正常运行。
失败通常会阻止对于当前的、并可能所有接下来的客户端请求的响应。
和错误相对照，错误是意料之中的，并可以针对性编码的情况——例如，
在输入验证的过程中所发现的错误，
将作为消息的正常处理过程的一部分返回给客户端。
失败时意料之外的，
并且在系统能够恢复至（与之前）服务水平之前，需要进行干预。
这并不意味着失败总是致命的（fatal），
虽然在失败发生之后，
系统的一些能力可能会被降级。
错误是正常操作流程的预期部分，
在错误发生之后，
系统将会立即对其进行处理，
并将继续以相同的能力继续运行。

失败的例子有：硬件故障、由于资源耗尽而引起的进程的意外终止，以及导致内部状态损坏的程序缺陷。

## <a name="隔离"></a>隔离（以及"遏制"）
隔离可以定义为在时间和空间上的解耦。
在时间上的解耦意味着发送者和接收者可以拥有独立的生命周期——
他们不需要在同时存在以使相互通信成为可能。
通过在组件之间添加异步边界，
并通过消息传递实现了这一点。
空间上的解耦（定义为位置透明）意味着发送者和接收者不必运行在同一个进程中。
不管运维部门或者运行时本身决策的部署结构是多么的高效——
在应用程序的生命周期之类，这一切都可能会改变。




## <a name="位置透明性"></a>位置透明性
有[可伸缩性](#可伸缩性)的系统需要有适应性，并且能持续地针对需求变化做出反应，他们需要优雅且高效地增加和缩减规模。有一个很关键的洞见可以极大地简化这个问题：那就是意识到我们所有人都在进行分布式计算。无论我们在一个单独的节点上运行一个系统（其中有多个互相独立的 CPU 通过 QPI 链路进行通信），还是在一系列节点组成的集群上运行一个系统（其中有多个独立的机器通过网络进行通信），都能看到分布式计算的影子。充分接受这个事实，就意味着基于多核的垂直式扩展与基于集群的水平式扩展并无概念上的区别。

如果我们的所有[组件](#组件)都支持移动性，仅仅是把本地通信看做一种优化的手段，那么我们就无需事先定义一个静态的系统拓扑结构，也不必定义一个静态的部署模型。我们可以把这个决策留给运营人员在系统运行时考虑，让他们根据系统的实际使用情况做出调整与优化。

这种通过[异步的](#异步的)[消息传递](#消息驱动)以及运行时实例与其引用解耦而实现的空间上的解耦（参考[隔离](#隔离)的定义），就是我们所谓的位置透明性。位置透明性经常被错误理解为“透明的分布式计算”，但实际情况正相反：我们拥抱网络和它的所有局限——比如局部故障，网络割裂，消息的丢失，以及其异步性和基于消息的天然特性——通过把这些特性当做编程模型中的一等公民，而不是尽力基于网络去模拟进程内方法调度（如 RPC，XA 等方式那样）。关于位置透明性，我们的观点与 Waldo 等人所发表的 [A Note On Distributed Computing](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.7628) 中的观点完全一致。

## <a name="消息驱动"></a>消息驱动（与事件驱动相对照）
消息是一个数据项，它需要被发送到一个特定目的地。事件是一个信号，当[组件](#组件)在运行中达到某个给定状态时，就会发出信号。在一个消息驱动的系统中，可访问的接收者等待消息的到来并做出反应，无消息时它将处于休眠状态。在一个事件驱动的系统中，通知的监听者被附着在事件源之上，以便在事件出现时被调用。这意味着事件驱动的系统的关注焦点是可访问的事件源，而消息驱动的系统则尽力关注可访问的接收者。一条消息中可以包含一个已编码的事件作为它的载荷。

在一个事件驱动的系统中，因为事件消费链天然的短暂性，很难实现较高的可回复性：当处理过程已经开始，且监听者也已附着在事件源上以便对执行结果做出反应和变换时，这些监听者通常会以报告给原始客户端的方式直接处理成功运行状态和[故障](#故障)状态。另一方面，要想对组件的故障做出响应使其正常工作，需要处理的并不是那些与转瞬即逝的与客户端请求直接挂钩的故障，而是那些因为组件的整体健康状况出现问题才导致的故障。

## <a name="非阻塞的"></a>非阻塞的
在并发式编程中，当一个算法的各个线程始终在争夺资源，并且这些资源没有被互斥性的保护机制限制，不会出现线程的执行被不确定地延后的情况时，我们就说这个算法是非阻塞的。在实践中这种特性通常表现为 API 的特性，当[资源](#资源)可用时它允许算法访问这项资源；当资源当前不可用时，它会立刻返回消息告知调用者这项资源当前不可用，或者调用者对 API 的操作已经初始化但还未完成。针对一项资源的非阻塞 API 允许调用者去做其它的工作，而不是阻塞它们，让它们一直等待到这项资源变为可用状态。作为补充，还可以允许请求资源的客户端在服务端注册，以便当资源变为可用状态或操作已完成时，自动向客户端发送通知。

## <a name="协议"></a>协议
协议定义了在[组件](#组件)之间交换或传输消息的处理方法和礼节性规范。协议是一种公式化的描述，它界定了消息交换的参与者，协议的累积状态与允许发送的消息集合之间的关系。这意味着一个协议可以描述这样的：在任意给定时间点上，一个参与者可能会向另一个参与者发送怎样的消息。可以用消息交换的形式对协议做分类，一些通用的协议类别包括：请求-回复，重复的请求-回复（比如 HTTP 协议），发布-订阅以及流的形式（既有推的动作，又有拉的动作）。

与本地编程接口相对比，协议更加泛化，因为它可以包含两个以上的参与者，并且它预见到一系列消息交换；一个接口一次只能指定调用者和接受者之间的一种交互。

需要注意的是，这里定义的协议仅仅指定了需要发送哪些消息，而并没有说明如何发送这些消息：编码，解码（即编码解码器）以及运输机制属于实现细节，它们对于组件间如何使用这些协议而言是透明的。

## <a name="复制"></a>复制
同时从不同的位置执行同一个[组件](#组件)的动作，被称为复制。复制可以在不同的线程或线程池中，不同的进程中，不同的网络节点或不同的计算中心执行。当进入的工作负载被分发到某个组件的多个实例上时，复制提供了[可扩展性](#可扩展性)；当进入的工作负载被复制到多个实例，每个实例都在并行地处理同一个请求时，复制提供了可伸缩性。这些方式可以被混合使用，例如确保所有与某个特定用户相关的交易所属的组件都被两个实例执行，而实例的总数则随着进入负载的变化而变化（参见[可伸缩性](#可伸缩性)）。

## <a name="资源"></a>资源
一个[组件](#组件)为了实现其功能而依赖的任何东西都可以称作资源，资源的特点是，必须根据组件的需要把它们预先提供出来。典型的资源包括 CPU、主内存、持久存储和网络带宽，主内存带宽，CPU 缓存，套接字之间的 CPU 链接，可靠的计时器和任务排程服务，其它输入与输出设备，外部服务如数据库或网络文件系统等。所有这些资源的[可伸缩性](#可伸缩性)与可回复性都需要被考虑到，因为任何一项所需资源的缺失都将导致这个组件在被要求发挥作用时无法正常工作。

## <a name="可扩展性"></a>可扩展性
可扩展性是指一个[系统](#系统)能够利用更多的计算[资源](#资源)提升其自身性能的能力，度量可扩展性的指标是吞吐量增量与资源增加的比值。一个完美可扩展的系统具有这样的特性，它的吞吐量增量与资源增加量是成正比的：当分配给系统的资源翻倍时，它的吞吐量也翻了一倍。可扩展性通常会因为引入了瓶颈或系统内的同步点而受到限制，导致受约束的可扩展性，参见 [Amdahl 法则与 Gunther 通用可扩展性模型](http://blogs.msdn.com/b/ddperf/archive/2009/04/29/parallel-scalability-isn-t-child-s-play-part-2-amdahl-s-law-vs-gunther-s-law.aspx)。

## <a name="系统"></a>系统
系统的作用是向[用户](#用户)或客户提供服务。系统可大可小，大的系统由较多[组件](#组件)组成，小的系统由有限的几个组件组成。系统的全部组件需要通力协作才能提供这些服务。在很多情况下，这些组件在整个系统中形成客户端-服务端关系（好比前端组件依赖后端组件）。一个系统共享同一个可回复性模型，这句话的意思是任何一个组件的[故障](#故障)都将在系统内部被处理，从一个组件[委派](#委派)给另一个组件。如果在某个系统中，一组组件相对于系统的其他部分而言，在功能、资源或故障模式等方面比较[隔离](#隔离)，那么不妨把它们视为一个子系统。

## <a name="用户"></a>用户
我们用这个术语表示使用一项服务的消费者，无论它是一个人还是另一项服务。
